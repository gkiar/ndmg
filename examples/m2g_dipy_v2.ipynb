{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KKI2009_113_1_DTI\n"
     ]
    }
   ],
   "source": [
    "# DIPY Experiments - m2g\n",
    "# W. Gray Roncal - January 22, 2016\n",
    "# Snowzilla\n",
    "\n",
    "# Params\n",
    "\n",
    "dwifile = 'KKI2009_113_1_DTI.nii'\n",
    "fbval = 'KKI2009_113_1_DTI.bval'\n",
    "fbvec = 'KKI2009_113_1_DTI.bvec'\n",
    "fatlas = 'MNI152_T1_1mm_brain.nii.gz'\n",
    "fatlas_labels = 'desikan.nii.gz'\n",
    "import os.path\n",
    "subLabel = os.path.splitext(dwifile)[0]\n",
    "print subLabel\n",
    "\n",
    "#TODO GK: build argparser, add m2rage, rename sublabel, output graphs\n",
    "\n",
    "#create: run_m2g_dipy.py that takes in file names and prints them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-values shape (33,)\n",
      "         min 0.000000 \n",
      "         max 700.000000 \n",
      "B-vectors shape (33, 3)\n",
      "         min -0.996763 \n",
      "         max 1.000000 \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "\n",
    "from dipy.io import read_bvals_bvecs, read_bvec_file\n",
    "from dipy.core.gradients import gradient_table\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "img = nib.load(dwifile)\n",
    "\n",
    "atlas_img = nib.load(fatlas)\n",
    "\n",
    "data = img.get_data()\n",
    "atlas = atlas_img.get_data()\n",
    "\n",
    "bvals, bvecs = read_bvals_bvecs(fbval, fbvec)\n",
    "\n",
    "# Get rid of spurrious scans\n",
    "idx = np.where((bvecs[:, 0] == 100) & (bvecs[:, 1] == 100) & (bvecs[:, 2] == 100))\n",
    "bvecs = np.delete(bvecs, idx, axis=0)\n",
    "bvals = np.delete(bvals, idx, axis=0)\n",
    "data = np.delete(data,idx,axis=3)\n",
    "\n",
    "gtab = gradient_table(bvals, bvecs, atol = 0.01) \n",
    "\n",
    "print gtab.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:09.761512\n"
     ]
    }
   ],
   "source": [
    "# Preprocess DTI\n",
    "\n",
    "# TODO - eddy correction!\n",
    "\n",
    "# Get b0\n",
    "b0 = np.where(gtab.b0s_mask)[0]\n",
    "b0_vol = np.squeeze(data[:, :, :, b0]) #if more than 1, just grab 1 for now.\n",
    "print datetime.now() - startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 65)\n",
      "(182, 218, 182)\n",
      "Optimizing level 2 [max iter: 10000]\n",
      "Optimizing level 1 [max iter: 1000]\n",
      "Optimizing level 0 [max iter: 100]\n",
      "Optimizing level 2 [max iter: 10000]\n",
      "Optimizing level 1 [max iter: 1000]\n",
      "Optimizing level 0 [max iter: 100]\n",
      "Optimizing level 2 [max iter: 10000]\n",
      "Optimizing level 1 [max iter: 1000]\n",
      "Optimizing level 0 [max iter: 100]\n",
      "0:18:54.496873\n"
     ]
    }
   ],
   "source": [
    "# Register to atlas \n",
    "# Register DTI to atlas \n",
    "#(B0 to MNI directly)\n",
    "\n",
    "from dipy.viz import regtools\n",
    "from dipy.data import fetch_stanford_hardi, read_stanford_hardi\n",
    "from dipy.data.fetcher import fetch_syn_data, read_syn_data\n",
    "from dipy.align.imaffine import (transform_centers_of_mass,\n",
    "                                 AffineMap,\n",
    "                                 MutualInformationMetric,\n",
    "                                 AffineRegistration)\n",
    "from dipy.align.transforms import (TranslationTransform3D,\n",
    "                                   RigidTransform3D,\n",
    "                                   AffineTransform3D)\n",
    "\n",
    "static_grid2world = atlas_img.get_affine()\n",
    "moving_grid2world = img.get_affine()\n",
    "\n",
    "# for compatibility with example code\n",
    "static = atlas\n",
    "moving = b0_vol\n",
    "\n",
    "print moving.shape\n",
    "print static.shape\n",
    "\"\"\"\n",
    "We can see that the images are far from aligned by drawing one on top of\n",
    "the other. The images don't even have the same number of voxels, so in order\n",
    "to draw one on top of the other we need to resample the moving image on a grid\n",
    "of the same dimensions as the static image, we can do this by \"transforming\"\n",
    "the moving image using an identity transform\n",
    "\"\"\"\n",
    "\n",
    "identity = np.eye(4)\n",
    "affine_map = AffineMap(identity,\n",
    "                       static.shape, static_grid2world,\n",
    "                       moving.shape, moving_grid2world)\n",
    "resampled = affine_map.transform(moving)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "We can obtain a very rough (and fast) registration by just aligning the centers\n",
    "of mass of the two images\n",
    "\"\"\"\n",
    "\n",
    "c_of_mass = transform_centers_of_mass(static, static_grid2world,\n",
    "                                      moving, moving_grid2world)\n",
    "\n",
    "\"\"\"\n",
    "We can now transform the moving image and draw it on top of the static image,\n",
    "registration is not likely to be good, but at least they will occupy roughly\n",
    "the same space\n",
    "\"\"\"\n",
    "\n",
    "transformed = c_of_mass.transform(moving)\n",
    "\n",
    "\"\"\"\n",
    "This was just a translation of the moving image towards the static image, now\n",
    "we will refine it by looking for an affine transform. We first create the\n",
    "similarity metric (Mutual Information) to be used. We need to specify the\n",
    "number of bins to be used to discretize the joint and marginal probability\n",
    "distribution functions (PDF), a typical value is 32. We also need to specify\n",
    "the percentage (an integer in (0, 100]) of voxels to be used for computing the\n",
    "PDFs, the most accurate registration will be obtained by using all voxels, but\n",
    "it is also the most time-consuming choice. We specify full sampling by passing\n",
    "None instead of an integer\n",
    "\"\"\"\n",
    "\n",
    "nbins = 32\n",
    "sampling_prop = None\n",
    "metric = MutualInformationMetric(nbins, sampling_prop)\n",
    "\n",
    "\"\"\"\n",
    "To avoid getting stuck at local optima, and to accelerate convergence, we use a\n",
    "multi-resolution strategy (similar to ANTS [Avants11]_) by building a Gaussian\n",
    "Pyramid. To have as much flexibility as possible, the user can specify how this\n",
    "Gaussian Pyramid is built. First of all, we need to specify how many\n",
    "resolutions we want to use. This is indirectly specified by just providing a\n",
    "list of the number of iterations we want to perform at each resolution. Here we\n",
    "will just specify 3 resolutions and a large number of iterations, 10000 at the\n",
    "coarsest resolution, 1000 at the medium resolution and 100 at the finest. These\n",
    "are the default settings\n",
    "\"\"\"\n",
    "\n",
    "level_iters = [10000, 1000, 100]\n",
    "\n",
    "\"\"\"\n",
    "To compute the Gaussian pyramid, the original image is first smoothed at each\n",
    "level of the pyramid using a Gaussian kernel with the requested sigma. A good\n",
    "initial choice is [3.0, 1.0, 0.0], this is the default\n",
    "\"\"\"\n",
    "\n",
    "sigmas = [3.0, 1.0, 0.0]\n",
    "\n",
    "\"\"\"\n",
    "Now we specify the sub-sampling factors. A good configuration is [4, 2, 1],\n",
    "which means that, if the original image shape was (nx, ny, nz) voxels, then the\n",
    "shape of the coarsest image will be about (nx//4, ny//4, nz//4), the shape in\n",
    "the middle resolution will be about (nx//2, ny//2, nz//2) and the image at the\n",
    "finest scale has the same size as the original image. This set of factors is\n",
    "the default\n",
    "\"\"\"\n",
    "\n",
    "factors = [4, 2, 1]\n",
    "\n",
    "\"\"\"\n",
    "Now we go ahead and instantiate the registration class with the configuration\n",
    "we just prepared\n",
    "\"\"\"\n",
    "\n",
    "affreg = AffineRegistration(metric=metric,\n",
    "                            level_iters=level_iters,\n",
    "                            sigmas=sigmas,\n",
    "                            factors=factors)\n",
    "\n",
    "\"\"\"\n",
    "Using AffineRegistration we can register our images in as many stages as we\n",
    "want, providing previous results as initialization for the next (the same logic\n",
    "as in ANTS). The reason why it is useful is that registration is a non-convex\n",
    "optimization problem (it may have more than one local optima), which means that\n",
    "it is very important to initialize as close to the solution as possible. For\n",
    "example, lets start with our (previously computed) rough transformation\n",
    "aligning the centers of mass of our images, and then refine it in three stages.\n",
    "First look for an optimal translation. The dictionary regtransforms contains\n",
    "all available transforms, we obtain one of them by providing its name and the\n",
    "dimension (either 2 or 3) of the image we are working with (since we are\n",
    "aligning volumes, the dimension is 3)\n",
    "\"\"\"\n",
    "\n",
    "transform = TranslationTransform3D()\n",
    "params0 = None\n",
    "starting_affine = c_of_mass.affine\n",
    "translation = affreg.optimize(static, moving, transform, params0,\n",
    "                              static_grid2world, moving_grid2world,\n",
    "                              starting_affine=starting_affine)\n",
    "\n",
    "\"\"\"\n",
    "If we look at the result, we can see that this translation is much better than\n",
    "simply aligning the centers of mass\n",
    "\"\"\"\n",
    "\n",
    "transformed = translation.transform(moving)\n",
    "\n",
    "\"\"\"\n",
    "Now lets refine with a rigid transform (this may even modify our previously\n",
    "found optimal translation)\n",
    "\"\"\"\n",
    "\n",
    "transform = RigidTransform3D()\n",
    "params0 = None\n",
    "starting_affine = translation.affine\n",
    "rigid = affreg.optimize(static, moving, transform, params0,\n",
    "                        static_grid2world, moving_grid2world,\n",
    "                        starting_affine=starting_affine)\n",
    "\n",
    "\"\"\"\n",
    "This produces a slight rotation, and the images are now better aligned\n",
    "\"\"\"\n",
    "\n",
    "transformed = rigid.transform(moving)\n",
    "\n",
    "\"\"\"\n",
    "Finally, lets refine with a full affine transform (translation, rotation, scale\n",
    "and shear), it is safer to fit more degrees of freedom now, since we must be\n",
    "very close to the optimal transform\n",
    "\"\"\"\n",
    "\n",
    "transform = AffineTransform3D()\n",
    "params0 = None\n",
    "starting_affine = rigid.affine\n",
    "affine = affreg.optimize(static, moving, transform, params0,\n",
    "                         static_grid2world, moving_grid2world,\n",
    "                         starting_affine=starting_affine)\n",
    "\n",
    "transformed = affine.transform(moving)\n",
    "\n",
    "print datetime.now() - startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182, 218, 182, 33)\n",
      "0:20:49.714946\n"
     ]
    }
   ],
   "source": [
    "# Apply transform\n",
    "# Loop through each of the DTI volumes for each of the transforms\n",
    "import igraph\n",
    "dwi_reg = np.zeros([transformed.shape[0],transformed.shape[1],transformed.shape[2],33])#data.shape[3]-1]) #TODO data.shape\n",
    "print dwi_reg.shape\n",
    "\n",
    "for x in range(dwi_reg.shape[3]):\n",
    "    moving = np.squeeze(data[:, :, :, x])    \n",
    "    transformed = c_of_mass.transform(moving)\n",
    "    transformed = translation.transform(moving)\n",
    "    transformed = rigid.transform(moving)\n",
    "    transformed = affine.transform(moving)\n",
    "    dwi_reg[:,:,:,x] = transformed\n",
    "print datetime.now() - startTime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B-values shape (33,)\n",
      "         min 0.000000 \n",
      "         max 700.000000 \n",
      "B-vectors shape (33, 3)\n",
      "         min -0.996763 \n",
      "         max 1.000000 \n",
      "(182, 218, 182, 33)\n",
      "tensors...\n",
      "0:40:19.875360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/dipy/reconst/csdeconv.py:576: UserWarning: maximum number of iterations exceeded - failed to converge\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python2.7/site-packages/dipy/reconst/csdeconv.py:576: UserWarning: maximum number of iterations exceeded - failed to converge\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python2.7/site-packages/dipy/reconst/csdeconv.py:576: UserWarning: maximum number of iterations exceeded - failed to converge\n",
      "  warnings.warn(msg)\n",
      "/usr/local/lib/python2.7/site-packages/dipy/reconst/csdeconv.py:576: UserWarning: maximum number of iterations exceeded - failed to converge\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Tensor estimation\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from dipy.reconst.dti import TensorModel, fractional_anisotropy\n",
    "from dipy.reconst.csdeconv import (ConstrainedSphericalDeconvModel,\n",
    "                                   auto_response)\n",
    "from dipy.direction import peaks_from_model\n",
    "from dipy.tracking.eudx import EuDX\n",
    "from dipy.data import fetch_stanford_hardi, read_stanford_hardi, get_sphere\n",
    "from dipy.segment.mask import median_otsu\n",
    "from dipy.viz import fvtk\n",
    "from dipy.viz.colormap import line_colors\n",
    "\n",
    "\n",
    "data = dwi_reg\n",
    "\n",
    "labeldata = nib.load(fatlas_labels)\n",
    "\n",
    "label = labeldata.get_data()\n",
    "\n",
    "\"\"\"\n",
    "Create a brain mask. Here we just threshold labels.\n",
    "\"\"\"\n",
    "\n",
    "mask = (label > 0)\n",
    "\n",
    "gtab.info\n",
    "print data.shape\n",
    "\"\"\"\n",
    "For the constrained spherical deconvolution we need to estimate the response\n",
    "function (see :ref:`example_reconst_csd`) and create a model.\n",
    "\"\"\"\n",
    "\n",
    "response, ratio = auto_response(gtab, data, roi_radius=10, fa_thr=0.7)\n",
    "\n",
    "csd_model = ConstrainedSphericalDeconvModel(gtab, response)\n",
    "\n",
    "\"\"\"\n",
    "Next, we use ``peaks_from_model`` to fit the data and calculated the fiber\n",
    "directions in all voxels.\n",
    "\"\"\"\n",
    "\n",
    "sphere = get_sphere('symmetric724')\n",
    "\n",
    "csd_peaks = peaks_from_model(model=csd_model,\n",
    "                             data=data,\n",
    "                             sphere=sphere,\n",
    "                             mask=mask,\n",
    "                             relative_peak_threshold=.5,\n",
    "                             min_separation_angle=25,\n",
    "                             parallel=True)\n",
    "\n",
    "\"\"\"\n",
    "For the tracking part, we will use the fiber directions from the ``csd_model``\n",
    "but stop tracking in areas where fractional anisotropy (FA) is low (< 0.1).\n",
    "To derive the FA, used here as a stopping criterion, we would need to fit a\n",
    "tensor model first. Here, we fit the Tensor using weighted least squares (WLS).\n",
    "\"\"\"\n",
    "print 'tensors...'\n",
    "\n",
    "tensor_model = TensorModel(gtab, fit_method='WLS')\n",
    "tensor_fit = tensor_model.fit(data, mask)\n",
    "\n",
    "FA = fractional_anisotropy(tensor_fit.evals)\n",
    "\n",
    "\"\"\"\n",
    "In order for the stopping values to be used with our tracking algorithm we need\n",
    "to have the same dimensions as the ``csd_peaks.peak_values``. For this reason,\n",
    "we can assign the same FA value to every peak direction in the same voxel in\n",
    "the following way.\n",
    "\"\"\"\n",
    "\n",
    "stopping_values = np.zeros(csd_peaks.peak_values.shape)\n",
    "stopping_values[:] = FA[..., None]\n",
    "print datetime.now() - startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:45:22.423110\n"
     ]
    }
   ],
   "source": [
    "# Fiber Tracking\n",
    "# TODO: better seeding\n",
    "\"\"\"\n",
    "``EuDX`` [Garyfallidis12]_ is a fast algorithm that we use here to generate\n",
    "streamlines. If the parameter ``seeds`` is a positive integer it will generate\n",
    "that number of randomly placed seeds everywhere in the volume. Alternatively,\n",
    "you can specify the exact seed points using an array (N, 3) where N is the\n",
    "number of seed points. For simplicity, here we will use the first option\n",
    "(random seeds). ``a_low`` is the threshold of the fist parameter\n",
    "(``stopping_values``) which means that there will that tracking will stop in\n",
    "regions with FA < 0.1.\n",
    "\"\"\"\n",
    "\n",
    "streamline_generator = EuDX(stopping_values,\n",
    "                            csd_peaks.peak_indices,\n",
    "                            seeds=10**6,\n",
    "                            odf_vertices=sphere.vertices,\n",
    "                            a_low=0.1)\n",
    "\n",
    "streamlines = [streamline for streamline in streamline_generator]\n",
    "\n",
    "print datetime.now() - startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(670701,)\n",
      "0\n",
      "25000\n",
      "50000\n",
      "75000\n",
      "100000\n",
      "125000\n",
      "150000\n",
      "175000\n",
      "200000\n",
      "225000\n",
      "250000\n",
      "275000\n",
      "300000\n",
      "325000\n",
      "350000\n",
      "375000\n",
      "400000\n",
      "425000\n",
      "450000\n",
      "475000\n",
      "500000\n",
      "525000\n",
      "550000\n",
      "575000\n",
      "600000\n",
      "625000\n",
      "650000\n",
      "0:02:01.974643\n"
     ]
    }
   ],
   "source": [
    "# Graph gen (non-scalable for now)\n",
    "#print label(ss)\n",
    "# initialize graph\n",
    "# For each streamline, round values\n",
    "# index into array and get all unique labels\n",
    "# for every n choose 2 ids, increment graph\n",
    "# plot graph\n",
    "# save graph\n",
    "\n",
    "startTime = datetime.now()\n",
    "\n",
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "import matplotlib.pylab as plt\n",
    "#G = nx.Graph()\n",
    "\n",
    "\n",
    "G = np.zeros((70,70))\n",
    "\n",
    "print np.shape(streamlines)\n",
    "\n",
    "for y in range(np.shape(streamlines)[0]):\n",
    "    \n",
    "    if (y % 25000) == 0:\n",
    "        print y\n",
    "    ss = (np.round(streamlines[y]))\n",
    "    ss = ss.astype(int)\n",
    "    f = []\n",
    "\n",
    "    for x in range(ss.shape[0]):\n",
    "        f.append(label[ss[x][0],ss[x][1],ss[x][2]])\n",
    "\n",
    "    f = np.unique(f)\n",
    "    f = f[f != 0]\n",
    "    ff = list(combinations(f,2))\n",
    "\n",
    "    for z in range(np.shape(ff)[0]):\n",
    "        G[ff[z][0]-1,ff[z][1]-1] = G[ff[z][0]-1,ff[z][1]-1] + 1\n",
    "        \n",
    "print datetime.now() - startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.00000000e+00   8.19000000e+03   3.86100000e+03 ...,   1.22000000e+02\n",
      "    4.00000000e+00   4.70000000e+01]\n",
      " [  0.00000000e+00   0.00000000e+00   2.35000000e+02 ...,   0.00000000e+00\n",
      "    0.00000000e+00   4.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   1.30000000e+01\n",
      "    0.00000000e+00   6.00000000e+00]\n",
      " ..., \n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    1.00000000e+00   1.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   3.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print G\n",
    "import numpy as np\n",
    "np.save('dipygraph.npy', G) #because things kept dying I wanted to keep the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "g = ig.Graph.Weighted_Adjacency(list(G), mode='undirected', attr='weight')\n",
    "g.save('thefilenameyouwant.graphml', format='graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a123c51f2807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_aspect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'equal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mG2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_aspect('equal')\n",
    "G2 = G + np.transpose(G)\n",
    "plt.imshow(np.log10(G2), interpolation='nearest', cmap=plt.cm.hot)\n",
    "plt.colorbar()\n",
    "plt.savefig(subLabel+'.png')\n",
    "\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(subLabel+'.csv', 'w') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=',')\n",
    "    #for x in range(G2.shape[0]):    \n",
    "    csvwriter.writerows(G2)   \n",
    "    \n",
    "    #TODO GK: output G as graphml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'G' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d37460abe9ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'G' is not defined"
     ]
    }
   ],
   "source": [
    "print G\n",
    "len(G)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
